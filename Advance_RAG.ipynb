{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNF2O33/dlM0Qr9FLkwFXS+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MudasirIrshad/Agentic_AI_Panaversity_Course/blob/main/Advance_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1AD0XZr6DzcU"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade --quiet  langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import langchain_google_genai as genai"
      ],
      "metadata": {
        "id": "Dl0uw2w8f5rA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LDBttxhQkiFV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\",\n",
        "    google_api_key=userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "TVwguNPJgEtQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"The Eiffel Tower is one of the most visited landmarks in the world.\",\n",
        "        metadata={\"source\": \"https://travel.com/eiffel-tower\", \"category\": \"travel\", \"author\": \"John Doe\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Python is a versatile language used in web development, data science, and automation.\",\n",
        "        metadata={\"source\": \"https://techblog.com/python-intro\", \"category\": \"technology\", \"author\": \"Jane Smith\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"The 2024 Summer Olympics will be held in Paris, France.\",\n",
        "        metadata={\"source\": \"https://sportsnews.com/olympics-2024\", \"category\": \"sports\", \"region\": \"Europe\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A balanced diet includes protein, carbs, fats, and plenty of water.\",\n",
        "        metadata={\"source\": \"https://healthline.com/nutrition/balanced-diet\", \"category\": \"health\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Bitcoin has outperformed traditional stocks over the last decade.\",\n",
        "        metadata={\"source\": \"https://cryptoalert.com/bitcoin-performance\", \"category\": \"finance\", \"year\": \"2025\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"AI is revolutionizing the medical industry through diagnostics and personalized care.\",\n",
        "        metadata={\"source\": \"https://medai.com/ai-in-healthcare\", \"category\": \"technology\", \"field\": \"healthcare\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Climate change is leading to more extreme weather events globally.\",\n",
        "        metadata={\"source\": \"https://eco.org/climate-change-effects\", \"category\": \"environment\", \"urgency\": \"high\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Shakespeare’s plays are still relevant in today’s world.\",\n",
        "        metadata={\"source\": \"https://literature.org/shakespeare\", \"category\": \"literature\", \"author\": \"William Shakespeare\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"React and Next.js are popular frameworks for building modern web applications.\",\n",
        "        metadata={\"source\": \"https://frontendweekly.com/react-vs-next\", \"category\": \"webdev\"}\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"The Mars Rover sent new images of the Martian landscape.\",\n",
        "        metadata={\"source\": \"https://nasa.gov/mars-rover-photos\", \"category\": \"space\", \"source_type\": \"official\"}\n",
        "    ),\n",
        "]\n"
      ],
      "metadata": {
        "id": "mu-XtLYAhrT_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU chromadb langchain-chroma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zen2pwZOh-g8",
        "outputId": "991c29a2-1f9e-484d-9675-0549b41bba11"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "vectorstore = Chroma.from_documents(documents, embeddings)\n",
        "vectorstore.similarity_search(\"event\",k=1)[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2m86eVZ2kBJj",
        "outputId": "98f74e28-2a4f-4935-a9be-a8afcf6a8edc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Climate change is leading to more extreme weather events globally.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU google-generativeai"
      ],
      "metadata": {
        "id": "o7krmLW1lMnv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "import google.generativeai as genai\n",
        "\n",
        "list(genai.list_models())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3Q27I0V6nl9n",
        "outputId": "cce2fedc-13e4-4c39-cc2c-cbc18ef41f65"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.5-pro-preview-03-25',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-03-25',\n",
              "       display_name='Gemini 2.5 Pro Preview 03-25',\n",
              "       description='Gemini 2.5 Pro Preview 03-25',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-preview-05-20',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-20',\n",
              "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
              "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 2.5 Flash',\n",
              "       description=('Stable version of Gemini 2.5 Flash, our mid-size multimodal model that '\n",
              "                    'supports up to 1 million tokens, released in June of 2025.'),\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-lite-preview-06-17',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-06-17',\n",
              "       display_name='Gemini 2.5 Flash-Lite Preview 06-17',\n",
              "       description='Preview release (June 11th, 2025) of Gemini 2.5 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-pro-preview-05-06',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-06',\n",
              "       display_name='Gemini 2.5 Pro Preview 05-06',\n",
              "       description='Preview release (May 6th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-pro-preview-06-05',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-06-05',\n",
              "       display_name='Gemini 2.5 Pro Preview',\n",
              "       description='Preview release (June 5th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-pro',\n",
              "       base_model_id='',\n",
              "       version='2.5',\n",
              "       display_name='Gemini 2.5 Pro',\n",
              "       description='Stable release (June 17th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash',\n",
              "       description='Gemini 2.0 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash 001',\n",
              "       description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in January of 2025.'),\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp-image-generation',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash (Image Generation) Experimental',\n",
              "       description='Gemini 2.0 Flash (Image Generation) Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite 001',\n",
              "       description='Stable version of Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite',\n",
              "       description='Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-preview-image-generation',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Preview Image Generation',\n",
              "       description='Gemini 2.0 Flash Preview Image Generation',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-pro-exp',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.0 Pro Experimental',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-pro-exp-02-05',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini 2.0 Pro Experimental 02-05',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='2.5-exp-03-25',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-20',\n",
              "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
              "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-20',\n",
              "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
              "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.5-preview-05-20',\n",
              "       display_name='Gemini 2.5 Flash Preview 05-20',\n",
              "       description='Preview release (April 17th, 2025) of Gemini 2.5 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-preview-tts',\n",
              "       base_model_id='',\n",
              "       version='gemini-2.5-flash-exp-tts-2025-05-19',\n",
              "       display_name='Gemini 2.5 Flash Preview TTS',\n",
              "       description='Gemini 2.5 Flash Preview TTS',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=16384,\n",
              "       supported_generation_methods=['countTokens', 'generateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-pro-preview-tts',\n",
              "       base_model_id='',\n",
              "       version='gemini-2.5-pro-preview-tts-2025-05-19',\n",
              "       display_name='Gemini 2.5 Pro Preview TTS',\n",
              "       description='Gemini 2.5 Pro Preview TTS',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=16384,\n",
              "       supported_generation_methods=['countTokens', 'generateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-2.0-flash-experimental',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='LearnLM 2.0 Flash Experimental',\n",
              "       description='LearnLM 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=32768,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-1b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 1B',\n",
              "       description='',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-4b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 4B',\n",
              "       description='',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-12b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 12B',\n",
              "       description='',\n",
              "       input_token_limit=32768,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3-27b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3 27B',\n",
              "       description='',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3n-e4b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3n E4B',\n",
              "       description='',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemma-3n-e2b-it',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemma 3n E2B',\n",
              "       description='',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=2048,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-lite',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 2.5 Flash-Lite',\n",
              "       description='Stable verion of Gemini 2.5 Flash-Lite, released in July of 2025',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent',\n",
              "                                     'countTokens',\n",
              "                                     'createCachedContent',\n",
              "                                     'batchGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp-03-07',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental 03-07',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-exp',\n",
              "       base_model_id='',\n",
              "       version='exp-03-07',\n",
              "       display_name='Gemini Embedding Experimental',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=8192,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent', 'countTextTokens', 'countTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40),\n",
              " Model(name='models/imagen-3.0-generate-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Imagen 3.0 002 model',\n",
              "       description='Vertex served Imagen 3.0 002 model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/imagen-4.0-generate-preview-06-06',\n",
              "       base_model_id='',\n",
              "       version='01',\n",
              "       display_name='Imagen 4 (Preview)',\n",
              "       description='Vertex served Imagen 4.0 model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/imagen-4.0-ultra-generate-preview-06-06',\n",
              "       base_model_id='',\n",
              "       version='01',\n",
              "       display_name='Imagen 4 Ultra (Preview)',\n",
              "       description='Vertex served Imagen 4.0 ultra model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/veo-2.0-generate-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Veo 2',\n",
              "       description=('Vertex served Veo 2 model. Access to this model requires billing to be '\n",
              "                    'enabled on the associated Google Cloud Platform account. Please visit '\n",
              "                    'https://console.cloud.google.com/billing to enable it.'),\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predictLongRunning'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/veo-3.0-generate-preview',\n",
              "       base_model_id='',\n",
              "       version='3.0',\n",
              "       display_name='Veo 3',\n",
              "       description=('Veo 3 preview. Access to this model requires billing to be enabled on the '\n",
              "                    'associated Google Cloud Platform account. Please visit '\n",
              "                    'https://console.cloud.google.com/billing to enable it.'),\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predictLongRunning'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-2.5-flash-preview-native-audio-dialog',\n",
              "       base_model_id='',\n",
              "       version='gemini-2.5-flash-preview-native-audio-dialog-2025-05-19',\n",
              "       display_name='Gemini 2.5 Flash Preview Native Audio Dialog',\n",
              "       description='Gemini 2.5 Flash Preview Native Audio Dialog',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-exp-native-audio-thinking-dialog',\n",
              "       base_model_id='',\n",
              "       version='gemini-2.5-flash-exp-native-audio-thinking-dialog-2025-05-19',\n",
              "       display_name='Gemini 2.5 Flash Exp Native Audio Thinking Dialog',\n",
              "       description='Gemini 2.5 Flash Exp Native Audio Thinking Dialog',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-live-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 2.0 Flash 001',\n",
              "       description='Gemini 2.0 Flash 001',\n",
              "       input_token_limit=131072,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-live-2.5-flash-preview',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini Live 2.5 Flash Preview',\n",
              "       description='Gemini Live 2.5 Flash Preview',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.5-flash-live-preview',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 2.5 Flash Live Preview',\n",
              "       description='Gemini 2.5 Flash Live Preview',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['bidiGenerateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "result: Dict = genai.embed_content(\n",
        "    content=\"The Mars Rover sent new images of the Martian landscape.\",\n",
        "    model = \"models/text-embedding-004\",\n",
        "    task_type=\"retrieval_document\",\n",
        "    title=\"ABC\"\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IrvWkbJ2njIt",
        "outputId": "c11b7843-a889-424a-8916-f5598c277aad"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'embedding': [0.0067029847,\n",
              "  -0.0051638456,\n",
              "  -0.0021967692,\n",
              "  0.030527072,\n",
              "  -0.002507369,\n",
              "  0.0099347625,\n",
              "  -0.010672472,\n",
              "  -0.05345437,\n",
              "  -0.0052493946,\n",
              "  0.084299155,\n",
              "  -0.056839876,\n",
              "  0.017651483,\n",
              "  0.029708853,\n",
              "  -0.011799941,\n",
              "  0.0030612599,\n",
              "  -0.00986444,\n",
              "  0.04628925,\n",
              "  0.015770318,\n",
              "  -0.06013165,\n",
              "  0.014067589,\n",
              "  0.01030875,\n",
              "  -0.028206268,\n",
              "  0.018350236,\n",
              "  -0.007297986,\n",
              "  -0.039907962,\n",
              "  0.046423186,\n",
              "  0.028096927,\n",
              "  0.04712208,\n",
              "  0.0057412446,\n",
              "  -0.002605931,\n",
              "  -0.003287141,\n",
              "  0.021030564,\n",
              "  0.054298144,\n",
              "  -0.029233651,\n",
              "  -0.010433987,\n",
              "  0.0066256546,\n",
              "  -0.05243017,\n",
              "  0.018546795,\n",
              "  0.00014959331,\n",
              "  -0.038050953,\n",
              "  -0.081055164,\n",
              "  0.056187477,\n",
              "  0.032259524,\n",
              "  0.074407876,\n",
              "  0.019027198,\n",
              "  0.03381847,\n",
              "  0.029232543,\n",
              "  -0.017237112,\n",
              "  -0.0036236835,\n",
              "  0.053126145,\n",
              "  -0.01823629,\n",
              "  0.036241904,\n",
              "  -0.01955441,\n",
              "  0.08214342,\n",
              "  -0.021279966,\n",
              "  0.016587306,\n",
              "  -0.05951481,\n",
              "  -0.037824612,\n",
              "  0.055919293,\n",
              "  0.004891685,\n",
              "  -0.012716108,\n",
              "  0.015741412,\n",
              "  0.00033912106,\n",
              "  0.026451703,\n",
              "  -0.0030457983,\n",
              "  -0.09234887,\n",
              "  -0.012741961,\n",
              "  0.0064057913,\n",
              "  -0.04091479,\n",
              "  0.028561857,\n",
              "  -0.0024492387,\n",
              "  0.09055173,\n",
              "  0.032096885,\n",
              "  -0.027532527,\n",
              "  -0.039655633,\n",
              "  -0.03392937,\n",
              "  -0.022082828,\n",
              "  -0.03812838,\n",
              "  0.020993166,\n",
              "  0.056733605,\n",
              "  -0.062897086,\n",
              "  -0.009064198,\n",
              "  0.04451501,\n",
              "  0.11535404,\n",
              "  0.01711961,\n",
              "  0.031273015,\n",
              "  0.05007425,\n",
              "  -0.006051821,\n",
              "  -0.11746308,\n",
              "  -0.0011795396,\n",
              "  0.060435828,\n",
              "  -0.04687784,\n",
              "  0.003803529,\n",
              "  -0.0049341405,\n",
              "  0.027386488,\n",
              "  0.04980242,\n",
              "  -0.090884276,\n",
              "  -0.095287584,\n",
              "  0.067076385,\n",
              "  -0.0014773527,\n",
              "  -0.015720604,\n",
              "  -0.028755102,\n",
              "  0.0048488206,\n",
              "  -0.034446016,\n",
              "  0.01699512,\n",
              "  0.039708298,\n",
              "  -0.020486552,\n",
              "  -0.028703533,\n",
              "  -0.011376061,\n",
              "  -0.00095639547,\n",
              "  -0.069302395,\n",
              "  -0.014139845,\n",
              "  -0.016349355,\n",
              "  0.032946378,\n",
              "  -0.031632416,\n",
              "  -0.030383425,\n",
              "  -0.038573593,\n",
              "  -0.01594902,\n",
              "  -0.06712707,\n",
              "  0.028504547,\n",
              "  -0.015925338,\n",
              "  -0.002146252,\n",
              "  0.009874565,\n",
              "  0.005555098,\n",
              "  0.06913153,\n",
              "  0.029924497,\n",
              "  -0.03449466,\n",
              "  0.007792152,\n",
              "  -0.03207391,\n",
              "  -0.03674095,\n",
              "  -0.006021948,\n",
              "  -0.09720962,\n",
              "  0.022623274,\n",
              "  0.039865702,\n",
              "  -0.044049025,\n",
              "  -0.0992361,\n",
              "  0.044072565,\n",
              "  0.063135944,\n",
              "  -0.009121501,\n",
              "  -0.011675386,\n",
              "  0.05452309,\n",
              "  0.0011299237,\n",
              "  -0.045912135,\n",
              "  0.010235154,\n",
              "  0.022303749,\n",
              "  0.018807316,\n",
              "  -0.00068492215,\n",
              "  0.0015640866,\n",
              "  -0.048343766,\n",
              "  -0.029809553,\n",
              "  -0.055479184,\n",
              "  -0.022050448,\n",
              "  -0.035472784,\n",
              "  -0.061296023,\n",
              "  -0.02224205,\n",
              "  -0.018479526,\n",
              "  0.034552947,\n",
              "  -0.062889956,\n",
              "  0.024459349,\n",
              "  -0.057949606,\n",
              "  0.017559305,\n",
              "  -0.027963802,\n",
              "  0.03416648,\n",
              "  0.03980236,\n",
              "  -0.009853097,\n",
              "  0.0055933525,\n",
              "  0.010488467,\n",
              "  -0.028399212,\n",
              "  -0.002283324,\n",
              "  -0.016061239,\n",
              "  0.021604236,\n",
              "  -0.048502285,\n",
              "  -0.027084699,\n",
              "  -0.075995415,\n",
              "  -0.037363496,\n",
              "  0.020872012,\n",
              "  -0.01666723,\n",
              "  -0.017667374,\n",
              "  -0.019908544,\n",
              "  -0.053446043,\n",
              "  0.10583015,\n",
              "  -0.05564646,\n",
              "  0.0076829162,\n",
              "  -0.042878028,\n",
              "  0.0053953263,\n",
              "  0.0923019,\n",
              "  0.02198244,\n",
              "  -0.025583925,\n",
              "  0.030968085,\n",
              "  0.03932098,\n",
              "  -0.020951556,\n",
              "  -0.041137584,\n",
              "  0.03195367,\n",
              "  0.043390643,\n",
              "  -0.011477432,\n",
              "  0.008632615,\n",
              "  0.015654488,\n",
              "  -0.100444086,\n",
              "  -0.019102395,\n",
              "  -0.03150209,\n",
              "  -0.0024396698,\n",
              "  0.08058829,\n",
              "  0.0031022476,\n",
              "  -0.010345093,\n",
              "  0.032685027,\n",
              "  0.0139976395,\n",
              "  -0.023168603,\n",
              "  -0.06552388,\n",
              "  0.008891033,\n",
              "  0.0101656495,\n",
              "  -0.048002023,\n",
              "  0.0076682,\n",
              "  -0.06795816,\n",
              "  -0.031442758,\n",
              "  -0.0021625087,\n",
              "  -0.018587358,\n",
              "  0.08415601,\n",
              "  0.0073978524,\n",
              "  0.04044751,\n",
              "  -0.051484603,\n",
              "  0.013441942,\n",
              "  0.02170506,\n",
              "  0.03607449,\n",
              "  -0.0012605629,\n",
              "  -0.009698289,\n",
              "  -0.027077,\n",
              "  -0.039474756,\n",
              "  -0.027248567,\n",
              "  0.048628695,\n",
              "  -0.034915768,\n",
              "  0.0069261095,\n",
              "  -0.0071443957,\n",
              "  -0.06025204,\n",
              "  -0.0026811336,\n",
              "  -0.03538998,\n",
              "  0.056036863,\n",
              "  0.026642699,\n",
              "  -0.059045903,\n",
              "  0.0054549514,\n",
              "  -0.0113529805,\n",
              "  -0.010579188,\n",
              "  -0.013296757,\n",
              "  0.0034497858,\n",
              "  0.024839599,\n",
              "  0.0065358365,\n",
              "  -0.029934533,\n",
              "  0.05293111,\n",
              "  0.04753049,\n",
              "  -0.0026141845,\n",
              "  -0.08044993,\n",
              "  -0.0061001033,\n",
              "  0.005136066,\n",
              "  -0.03596234,\n",
              "  0.011052715,\n",
              "  -0.03905399,\n",
              "  -0.05470421,\n",
              "  0.04238122,\n",
              "  -0.006162971,\n",
              "  0.0046514207,\n",
              "  -0.0071283737,\n",
              "  0.014941361,\n",
              "  -0.030508311,\n",
              "  0.0500353,\n",
              "  -0.043427408,\n",
              "  -0.042091157,\n",
              "  -0.084705584,\n",
              "  -0.03869259,\n",
              "  0.010043335,\n",
              "  -0.01715275,\n",
              "  -0.04599429,\n",
              "  -0.018043814,\n",
              "  0.016773239,\n",
              "  -0.0396569,\n",
              "  0.022922901,\n",
              "  -0.03747535,\n",
              "  0.045301054,\n",
              "  0.04461385,\n",
              "  0.04629709,\n",
              "  0.016771458,\n",
              "  -0.05492512,\n",
              "  -0.03656032,\n",
              "  0.020817231,\n",
              "  -0.015414939,\n",
              "  -0.055036068,\n",
              "  -0.0043140966,\n",
              "  -0.036410943,\n",
              "  -0.023903996,\n",
              "  0.021592237,\n",
              "  -0.007881027,\n",
              "  -0.01319664,\n",
              "  -0.017541679,\n",
              "  0.083179295,\n",
              "  0.010776834,\n",
              "  0.0021727725,\n",
              "  0.029742349,\n",
              "  -0.0120867165,\n",
              "  -0.02494342,\n",
              "  0.063923374,\n",
              "  -0.03133315,\n",
              "  -0.005662812,\n",
              "  -0.014259789,\n",
              "  0.068365805,\n",
              "  -0.009248108,\n",
              "  -0.027865438,\n",
              "  0.011675031,\n",
              "  -0.030989317,\n",
              "  -0.062808126,\n",
              "  -0.050841752,\n",
              "  -0.009998713,\n",
              "  0.04009955,\n",
              "  0.024048246,\n",
              "  0.04324296,\n",
              "  0.0026332084,\n",
              "  -0.025951028,\n",
              "  -0.037733197,\n",
              "  -0.021577697,\n",
              "  -0.13448752,\n",
              "  -0.021363998,\n",
              "  -0.013237572,\n",
              "  0.007559414,\n",
              "  0.016730033,\n",
              "  0.028128076,\n",
              "  -0.053500853,\n",
              "  0.028714027,\n",
              "  0.05722547,\n",
              "  -0.034819867,\n",
              "  -0.0058717118,\n",
              "  0.01261621,\n",
              "  0.03462887,\n",
              "  0.030359367,\n",
              "  -0.016267186,\n",
              "  0.023707792,\n",
              "  -0.07453938,\n",
              "  -0.004252013,\n",
              "  -0.018479638,\n",
              "  0.0067850775,\n",
              "  -0.019099047,\n",
              "  0.020600308,\n",
              "  0.043714106,\n",
              "  0.028000452,\n",
              "  0.039370816,\n",
              "  0.027342029,\n",
              "  0.012559544,\n",
              "  0.08286419,\n",
              "  -0.03250231,\n",
              "  -0.03154061,\n",
              "  0.040781863,\n",
              "  -0.0040581794,\n",
              "  -0.0045361943,\n",
              "  -0.053672306,\n",
              "  0.04641847,\n",
              "  0.050679006,\n",
              "  0.07703268,\n",
              "  -0.039985508,\n",
              "  -0.040929276,\n",
              "  -0.032504406,\n",
              "  0.026701458,\n",
              "  -0.05423818,\n",
              "  0.0150903845,\n",
              "  -0.037103835,\n",
              "  -0.015184772,\n",
              "  0.00741284,\n",
              "  -0.020903299,\n",
              "  -0.0048003546,\n",
              "  0.0132414745,\n",
              "  -0.01860872,\n",
              "  -0.016562458,\n",
              "  0.03407649,\n",
              "  -0.045638062,\n",
              "  -0.05332369,\n",
              "  0.011152959,\n",
              "  0.021670032,\n",
              "  0.008208537,\n",
              "  0.009325885,\n",
              "  -0.00787796,\n",
              "  -0.009732633,\n",
              "  -0.030944014,\n",
              "  0.015620628,\n",
              "  -0.014241827,\n",
              "  -0.02094446,\n",
              "  -0.017981865,\n",
              "  -0.0193911,\n",
              "  -0.035727654,\n",
              "  0.062341392,\n",
              "  0.022177827,\n",
              "  0.07352278,\n",
              "  -0.058706846,\n",
              "  0.047888227,\n",
              "  -0.0037402308,\n",
              "  0.033537902,\n",
              "  -0.013891663,\n",
              "  0.026524136,\n",
              "  0.032142002,\n",
              "  0.018487077,\n",
              "  0.023288438,\n",
              "  0.031230062,\n",
              "  -0.022188485,\n",
              "  0.011185745,\n",
              "  0.06732815,\n",
              "  0.018005824,\n",
              "  0.023757253,\n",
              "  0.029282464,\n",
              "  0.061374806,\n",
              "  -0.015374605,\n",
              "  0.010241429,\n",
              "  -0.0075718374,\n",
              "  0.057332404,\n",
              "  0.018087195,\n",
              "  0.0142648015,\n",
              "  -0.057415165,\n",
              "  0.00028077813,\n",
              "  0.0063965362,\n",
              "  -0.011279827,\n",
              "  -0.036445204,\n",
              "  -0.043729458,\n",
              "  -0.05540301,\n",
              "  0.042387385,\n",
              "  -0.009060834,\n",
              "  -0.009262469,\n",
              "  0.034774613,\n",
              "  -0.016085299,\n",
              "  -0.002541057,\n",
              "  -0.0029358969,\n",
              "  -0.015295631,\n",
              "  -0.0039003736,\n",
              "  -0.050212324,\n",
              "  -0.024264649,\n",
              "  0.0026967095,\n",
              "  0.014002271,\n",
              "  -0.034381017,\n",
              "  -0.004969636,\n",
              "  0.023356633,\n",
              "  -0.038884457,\n",
              "  0.0224049,\n",
              "  0.025556963,\n",
              "  -0.008548215,\n",
              "  0.008907386,\n",
              "  0.026650172,\n",
              "  0.0027976166,\n",
              "  -0.011982147,\n",
              "  -0.062238127,\n",
              "  0.018547604,\n",
              "  -0.014967654,\n",
              "  0.024903392,\n",
              "  0.0067870193,\n",
              "  0.016519414,\n",
              "  0.014992779,\n",
              "  -0.0093803285,\n",
              "  -0.03374349,\n",
              "  -0.013170852,\n",
              "  -0.015452887,\n",
              "  -0.02698482,\n",
              "  0.03297998,\n",
              "  -0.043270502,\n",
              "  -0.040501665,\n",
              "  -0.006831952,\n",
              "  0.007731364,\n",
              "  0.053097587,\n",
              "  -0.0064942855,\n",
              "  0.011668251,\n",
              "  -0.022363806,\n",
              "  -0.016643725,\n",
              "  0.05662798,\n",
              "  0.02448483,\n",
              "  0.027773658,\n",
              "  0.025550302,\n",
              "  0.040244035,\n",
              "  0.02310409,\n",
              "  -0.05157746,\n",
              "  0.052935965,\n",
              "  0.07280779,\n",
              "  -0.026417384,\n",
              "  0.020838795,\n",
              "  0.029436773,\n",
              "  -0.009808939,\n",
              "  -0.0050429245,\n",
              "  -0.0059289406,\n",
              "  0.010472807,\n",
              "  -0.005030176,\n",
              "  -0.031703416,\n",
              "  -0.032055408,\n",
              "  -0.0086681945,\n",
              "  -0.008738759,\n",
              "  0.019744141,\n",
              "  0.048493773,\n",
              "  -0.006320574,\n",
              "  -0.010365374,\n",
              "  0.0073361257,\n",
              "  -0.005028728,\n",
              "  0.011562462,\n",
              "  -0.0018099195,\n",
              "  0.030921346,\n",
              "  0.0039760782,\n",
              "  -0.01447048,\n",
              "  0.0027518037,\n",
              "  0.034730423,\n",
              "  0.022021523,\n",
              "  -0.026850568,\n",
              "  -0.011850389,\n",
              "  0.013375582,\n",
              "  0.035725158,\n",
              "  0.06482511,\n",
              "  -0.04831438,\n",
              "  -0.06306143,\n",
              "  -0.015570368,\n",
              "  0.03447915,\n",
              "  -0.037949875,\n",
              "  -0.009457945,\n",
              "  0.0038922366,\n",
              "  0.015307133,\n",
              "  -0.023999348,\n",
              "  0.023916554,\n",
              "  0.015110024,\n",
              "  -0.008228886,\n",
              "  -0.029559184,\n",
              "  0.07456461,\n",
              "  -0.022340886,\n",
              "  0.020387579,\n",
              "  -0.00942716,\n",
              "  0.025331374,\n",
              "  0.01532865,\n",
              "  -0.027706817,\n",
              "  0.010202429,\n",
              "  -0.04783237,\n",
              "  0.038861673,\n",
              "  -0.0065499297,\n",
              "  -0.027383307,\n",
              "  -0.022503989,\n",
              "  0.014620295,\n",
              "  -0.040926866,\n",
              "  -0.05820241,\n",
              "  0.06479391,\n",
              "  0.086970106,\n",
              "  0.021229845,\n",
              "  0.011299324,\n",
              "  0.1068189,\n",
              "  -0.00082911324,\n",
              "  0.06319336,\n",
              "  -0.002124046,\n",
              "  -0.014692139,\n",
              "  -0.0074698245,\n",
              "  -0.031610057,\n",
              "  -0.017154483,\n",
              "  0.06878442,\n",
              "  0.003907754,\n",
              "  0.0012008983,\n",
              "  0.041248646,\n",
              "  -0.030882852,\n",
              "  -0.005007549,\n",
              "  0.049007617,\n",
              "  -0.0088706575,\n",
              "  -0.057359733,\n",
              "  -0.016480748,\n",
              "  -0.00017113879,\n",
              "  -0.016858349,\n",
              "  0.030938283,\n",
              "  0.038849458,\n",
              "  -0.0526588,\n",
              "  -0.07113318,\n",
              "  -0.0067933504,\n",
              "  -0.008401072,\n",
              "  0.0070782816,\n",
              "  0.014752012,\n",
              "  0.01737454,\n",
              "  -0.04377407,\n",
              "  -0.037397858,\n",
              "  0.012571296,\n",
              "  0.046683673,\n",
              "  -0.027863046,\n",
              "  0.0029667888,\n",
              "  0.022087073,\n",
              "  -0.008128919,\n",
              "  -0.04367049,\n",
              "  -0.024750385,\n",
              "  -0.0047751446,\n",
              "  0.00093116687,\n",
              "  -0.004680921,\n",
              "  0.04055169,\n",
              "  0.04119019,\n",
              "  -0.023157526,\n",
              "  -0.004693766,\n",
              "  0.011491701,\n",
              "  0.037216872,\n",
              "  0.0018805749,\n",
              "  0.06490149,\n",
              "  -0.01244271,\n",
              "  -0.049317587,\n",
              "  0.017339759,\n",
              "  0.007751071,\n",
              "  -0.04015631,\n",
              "  -0.026039312,\n",
              "  0.040586747,\n",
              "  0.018812977,\n",
              "  -0.034983497,\n",
              "  0.06589464,\n",
              "  0.017130394,\n",
              "  -0.03529821,\n",
              "  0.0099587105,\n",
              "  -0.0046921424,\n",
              "  0.038236007,\n",
              "  -0.004754877,\n",
              "  -0.06673461,\n",
              "  0.016194653,\n",
              "  0.056587398,\n",
              "  0.00049984205,\n",
              "  -0.019171573,\n",
              "  -0.03841749,\n",
              "  -0.0633722,\n",
              "  -0.0013320087,\n",
              "  -0.048360873,\n",
              "  -0.012926856,\n",
              "  0.014598227,\n",
              "  0.020240147,\n",
              "  0.0237008,\n",
              "  -0.0022876395,\n",
              "  0.011495123,\n",
              "  -0.05393277,\n",
              "  -0.0029873068,\n",
              "  0.046068907,\n",
              "  0.030491982,\n",
              "  0.01233384,\n",
              "  0.06320222,\n",
              "  0.02867894,\n",
              "  -0.01602802,\n",
              "  -0.038043544,\n",
              "  -0.023312697,\n",
              "  0.025470154,\n",
              "  -0.014856162,\n",
              "  -0.033227667,\n",
              "  0.037135463,\n",
              "  -0.06775955,\n",
              "  -0.029399399,\n",
              "  -0.0022837487,\n",
              "  -0.028744467,\n",
              "  0.0043318896,\n",
              "  0.040551923,\n",
              "  -0.0294433,\n",
              "  0.021187771,\n",
              "  -0.031827375,\n",
              "  0.032396372,\n",
              "  -0.027164122,\n",
              "  -0.0041013854,\n",
              "  0.034030814,\n",
              "  0.019409537,\n",
              "  -0.04943519,\n",
              "  0.050801225,\n",
              "  -0.0050231074,\n",
              "  0.029765798,\n",
              "  0.024754712,\n",
              "  0.016206723,\n",
              "  -3.8909286e-05,\n",
              "  0.015043927,\n",
              "  -0.029310226,\n",
              "  -0.014446984,\n",
              "  -0.032897238,\n",
              "  0.020292735,\n",
              "  -0.063257486,\n",
              "  -0.021986168,\n",
              "  -0.022249885,\n",
              "  -0.0048527406,\n",
              "  -0.00473828,\n",
              "  0.016595013,\n",
              "  -0.00072448933,\n",
              "  0.011999564,\n",
              "  -0.0053734337,\n",
              "  0.013899356,\n",
              "  0.018977005,\n",
              "  0.013569388,\n",
              "  0.021853726,\n",
              "  -0.04185841,\n",
              "  -0.02092214,\n",
              "  -0.0102393525,\n",
              "  -0.01462184,\n",
              "  0.08456722,\n",
              "  -0.0357414,\n",
              "  0.014998923,\n",
              "  0.032376546,\n",
              "  -0.01394597,\n",
              "  -0.029189609,\n",
              "  -0.0064455504,\n",
              "  0.020016517,\n",
              "  -0.03160376,\n",
              "  -0.01723669,\n",
              "  -0.027177108,\n",
              "  0.021248844,\n",
              "  -0.03845091,\n",
              "  0.02258746,\n",
              "  -0.018960206,\n",
              "  -0.044832792,\n",
              "  0.0003516658,\n",
              "  -0.0046880473,\n",
              "  -0.048525237,\n",
              "  -0.06132925,\n",
              "  -0.084362864,\n",
              "  -0.0027186135,\n",
              "  0.022071565,\n",
              "  -0.026796045,\n",
              "  -0.008960755,\n",
              "  -0.0470383,\n",
              "  0.014588179,\n",
              "  -0.037570722,\n",
              "  0.017033163,\n",
              "  -0.08128733,\n",
              "  -0.035070855,\n",
              "  0.034558244,\n",
              "  0.049430303,\n",
              "  0.019241728,\n",
              "  -0.019154346,\n",
              "  -0.07069237,\n",
              "  -0.0031555027,\n",
              "  -0.034555145,\n",
              "  0.021437531,\n",
              "  0.02928714,\n",
              "  0.074499615,\n",
              "  0.012578837,\n",
              "  0.028356008,\n",
              "  0.030085796,\n",
              "  -0.03471664,\n",
              "  0.015391286,\n",
              "  0.019141885,\n",
              "  0.008966073,\n",
              "  0.007414636,\n",
              "  -0.00259833,\n",
              "  0.03868195,\n",
              "  0.041000467,\n",
              "  -0.038723033,\n",
              "  -0.06582763,\n",
              "  0.027400363,\n",
              "  -0.017628472,\n",
              "  0.07704126,\n",
              "  0.084099606,\n",
              "  -0.012183011,\n",
              "  -0.014761975,\n",
              "  0.06466877,\n",
              "  -0.0389288,\n",
              "  -0.015515938,\n",
              "  -0.009306896,\n",
              "  0.023391567,\n",
              "  0.052915897,\n",
              "  -0.07293838,\n",
              "  0.065564655,\n",
              "  -0.01465065,\n",
              "  -0.06914157,\n",
              "  0.04384433,\n",
              "  -0.028931065,\n",
              "  0.021066476,\n",
              "  -0.015638078,\n",
              "  -0.016713297,\n",
              "  -0.018959733,\n",
              "  0.0047105914,\n",
              "  -0.07889151,\n",
              "  0.014149446,\n",
              "  0.035409495,\n",
              "  -0.0046114195,\n",
              "  0.023222838,\n",
              "  -0.037931446,\n",
              "  -0.036793817,\n",
              "  -0.022665337,\n",
              "  0.037079934,\n",
              "  -0.0023541576,\n",
              "  -0.008740721,\n",
              "  0.027451692,\n",
              "  -0.009791411,\n",
              "  0.002499483,\n",
              "  -0.00950343,\n",
              "  -0.014176627,\n",
              "  0.056452334,\n",
              "  -0.035511788]}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wONW9kOVocDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}